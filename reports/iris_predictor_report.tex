% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother


% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}



\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={IrisSpeciesPredictor},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{IrisSpeciesPredictor}
\author{Tiffany Chu, Gaurang Ahuja, Nguyen Nguyen, Vienne Lee}
\date{}
\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}

\subsection{Summary}\label{summary}

This project investigates whether iris species can be predicted using
sepal and petal measurements. After loading and validating the dataset,
we explore some basic patterns, do some EDA and then train a model. The
overall results show that petal measurements provide strong separation
between species, allowing the models to achieve high accuracy.

\subsection{Introduction}\label{introduction}

The Iris dataset is a well-known benchmark in machine learning,
containing measurements of iris flowers collected to study how physical
characteristics differ across species.

\subsubsection{Feature Summary}\label{feature-summary}

There are 4 numerical features in this dataset:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{sepal\_length}: The length of the sepal (outer part of the
  flower)
\item
  \texttt{sepal\_width}: The width of the sepal
\item
  \texttt{petal\_length}: The length of the petal
\item
  \texttt{petal\_width}: The width of the petal
\end{enumerate}

There is 1 categorical feature in the dataset:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{species}: The target variable (label)
\end{enumerate}

We are using the Iris dataset to answer the question: \textbf{``Can we
predict the Iris species using petal and sepal measurements?''}

The data set contains 3 classes of 50 instances each, where each class
refers to a type of iris plant. One class is linearly separable from the
other 2; the latter are not linearly separable from each other (Fisher
1936).

\subsection{Methods \& Results}\label{methods-results}

\begin{longtable}[]{@{}llllll@{}}

\caption{\label{tbl-data}Preview of Iris Data}

\tabularnewline

\toprule\noalign{}
& sepal\_length & sepal\_width & petal\_length & petal\_width &
species \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 5.1 & 3.5 & 1.4 & 0.2 & setosa \\
1 & 4.9 & 3.0 & 1.4 & 0.2 & setosa \\
2 & 4.7 & 3.2 & 1.3 & 0.2 & setosa \\
3 & 4.6 & 3.1 & 1.5 & 0.2 & setosa \\
4 & 5.0 & 3.6 & 1.4 & 0.2 & setosa \\

\end{longtable}

\subsubsection{Basic Data Stats}\label{basic-data-stats}

In the code below, we check some basic stats for the dataframe such as
the number of rows, columns etc. We convert the columns names to a more
standard format using underscores and lowercase. We then check how many
unique species there are.

The training dataset has 104 rows and 5 columns.

\subsubsection{Data Wrangling}\label{data-wrangling}

Since our goal is classification, this section will look at statistics
which will help distinguish between the species. Therefore, we will look
at things like mean, median, min, max etc for each feature. This will be
followed by graphical analysis where we will explore bar plot, pairwise
plot, and boxplot.

\begin{longtable}[]{@{}lllll@{}}

\caption{\label{tbl-summary-numeric}Summary of numeric columns}

\tabularnewline

\toprule\noalign{}
& sepal\_length & sepal\_width & petal\_length & petal\_width \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
count & 104.000000 & 104.000000 & 104.000000 & 104.000000 \\
mean & 5.833654 & 3.048077 & 3.777885 & 1.228846 \\
std & 0.772917 & 0.408877 & 1.670937 & 0.740726 \\
min & 4.400000 & 2.200000 & 1.000000 & 0.100000 \\
25\% & 5.100000 & 2.800000 & 1.600000 & 0.375000 \\
50\% & 5.800000 & 3.000000 & 4.400000 & 1.300000 \\
75\% & 6.400000 & 3.300000 & 5.000000 & 1.800000 \\
max & 7.700000 & 4.400000 & 6.900000 & 2.500000 \\

\end{longtable}

\begin{longtable}[]{@{}lllllllll@{}}

\caption{\label{tbl-summary-species}Variation per species}

\tabularnewline

\toprule\noalign{}
& \multicolumn{2}{l}{%
sepal\_length} & \multicolumn{2}{l}{%
sepal\_width} & \multicolumn{2}{l}{%
petal\_length} & \multicolumn{2}{l@{}}{%
petal\_width} \\
& mean & std & mean & std & mean & std & mean & std \\
species & & & & & & & & \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
setosa & 5.000000 & 0.336011 & 3.415625 & 0.400894 & 1.471875 & 0.163104
& 0.25625 & 0.113415 \\
versicolor & 6.000000 & 0.505863 & 2.832500 & 0.283194 & 4.297500 &
0.460483 & 1.35000 & 0.196116 \\
virginica & 6.459375 & 0.626748 & 2.950000 & 0.290717 & 5.434375 &
0.559729 & 2.05000 & 0.265184 \\

\end{longtable}

\paragraph{Insights from Data
Statistics}\label{insights-from-data-statistics}

From the above tables, we can see:

\begin{itemize}
\tightlist
\item
  Most species have approximately the same number of observations
\item
  Petal measurements display the strongest separation
\item
  Setosa is distinct while versicolor and virginica show some overlap
\item
  Petal dimensions have meaningful differences
\end{itemize}

\subsection{EDA Plots}\label{eda-plots}

Below are the plots visualize the underlying patterns, distributions,
and relationships within the three features (\texttt{sepal\_length},
\texttt{sepal\_width}, \texttt{petal\_length}, \texttt{petal\_width}) in
the Iris dataset.

\subsubsection{Pairwise Plot}\label{pairwise-plot}

Pairwise plots show the relationships between feature pair and show any
clusters. Figure~\ref{fig-pairwise} helps identify which pair of
features show the clearest separation and allows us to identify which
features are the most informative for prediction.

\begin{figure}

\centering{

\includegraphics[width=0.9\linewidth,height=\textheight,keepaspectratio]{../results/figures/iris_species_pairwise.png}

}

\caption{\label{fig-pairwise}Pairwise Plot of Iris Features}

\end{figure}%

\subsubsection{Boxplot}\label{boxplot}

Figure~\ref{fig-boxplot} show how each feature varies across species.
The median, spread, outliers, and overlaps helps identify features that
are most predictive for classifying the Iris species.

\begin{figure}

\centering{

\includegraphics[width=0.6\linewidth,height=\textheight,keepaspectratio]{../results/figures/iris_species_boxplot.png}

}

\caption{\label{fig-boxplot}Boxplot of Iris Feature Variation}

\end{figure}%

\subsection{Model Training Results}\label{model-training-results}

We tried 2 models, below are the results of each.

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{./figures/dt_confusion.png}

}

\caption{\label{fig-dt_confusion}Decision Tree Confusion Matrix}

\end{figure}%

\begin{figure}

\centering{

\includegraphics[width=0.8\linewidth,height=\textheight,keepaspectratio]{./figures/knn_confusion.png}

}

\caption{\label{fig-knn_confusion}K-NN Confusion Matrix}

\end{figure}%

\subsection{Discussion and Analysis}\label{discussion-and-analysis}

In our investigation of the Iris dataset, we establish whether these
features are strong predictors for Iris species classification and rank
their predictive power. This discussion begins with the insights derived
from our in-depth exploratory data analysis, then the outcomes of our
machine learning models, and finally exploring the implications for
biological classification and machine learning practices for future
research.\\
To summarize the data, the Iris dataset consists of 150 samples with
measurements for four features: sepal length, sepal width, petal length,
and petal width, across three evenly distributed species: Setosa,
Versicolor, and Virginica.

In our exploratory data analysis (EDA), the summary statistics in
Table~\ref{tbl-summary-numeric} and Table~\ref{tbl-summary-species} show
that petal measurements (length and width) exhibit more obvious
differences across species compared to sepal feature measurements. Sepal
measurements are not as varied across species and thus provide weaker
separation when distinguishing species. Our visualizations of pairwise
feature plots in Figure~\ref{fig-pairwise}, and boxplots in
Figure~\ref{fig-boxplot} confirm these patterns, they each reveal the
power of petal measurement for distinguishing species during
classification. Specifically, the boxplot shows how the species Setosa
is easily distinguishable from just its petal measurements.

Both Decision Tree and KNN models perform strongly on this Iris test set
(95\% vs 93\% accuracy, respectively). Petal and sepal feature
differences allow decent separation between species, especially between
the species Versicolor and Virginica. The misclassifications in
confusion matrices show this overlap. The cross-validation results
suggest that Decision Trees with max\_depth values from 4 to 18 fit the
training data perfectly while achieving similarly high validation
accuracy (94.3\%) on unseen folds. For the KNN hyperparameter tuning,
findings show that choosing n\_neighbors between 4 and 12 outputs a
classification accuracy around 97\% on cross-validation test scores.

Examining our confusion matrix for model accuracies:

\begin{itemize}
\tightlist
\item
  In the decision tree test performance as seen in
  Figure~\ref{fig-dt_confusion}, Setosa was classified perfectly (as it
  is the most distinguishable), while 3 virginica got misclassified as
  versicolor.
\item
  In our KNN model Figure~\ref{fig-knn_confusion}, we find that setosa
  is perfect again, and KNN misclassifies: 1 versicolor as virginica,
  and 2 virginica as versicolor.
\item
  This is expected as the two classes (virginica and versicolor) overlap
  in features.
\end{itemize}

Our decision tree model is slightly better than KNN, with better
accuracy, fewer total mistakes, perfect versicolor classification,
though same performance on setosa and virginica. This suggests high but
not perfect predictability of iris species from its measurements, with
room for improving classification on overlapping species using more
advanced methods or additional features. These results demonstrate a
typical well-performing classification pipeline for the Iris dataset,
validating the exploratory and modeling insights

The findings that petal measurements strongly separate iris species and
have high model accuracy are expected and align with prior knowledge and
research on the Iris dataset. The petal length and width consistently
show clearer distinctions among the species, particularly separating
Setosa from Versicolor and Virginica, however, Sepal measurements tend
to show more overlap and offer weaker discriminatory power.

However, there are some limitations associated with our study, some key
limitations of the dataset and the related findings include: The dataset
contains only 150 samples with 4 numeric features and 3 species classes,
which is considered quite small and simple compared to data on other
plant species. This limits the complexity of patterns that can be
learned and makes it less applicable to more complex classification
tasks. Its size also prevents it from being useful for complex machine
learning techniques like deep learning, which require larger datasets.

Only sepal and petal measurements are considered, and other potentially
informative features such as genetic data, environmental variables, or
flower color are not recorded as features in the data. This constrains
prediction to specific traits and may limit generalizability to other
flowers or datasets.

It appears that the species Setosa is clearly separable, while
Versicolor and Virginica show overlap in some measurements, leading to
some classification errors and ambiguity that models must handle or risk
making errors. The dataset is clean with no missing values or
measurement noise, which is not typical/normal in many real datasets.
This means models trained here may be optimistic compared to actual real
world performance. So while appropriate for demonstrating classification
approaches and feature importance, the Iris dataset's limitations
prevent our model from being broadly applicable and generalizable, which
must be considered when interpreting and generalizing findings. We must
also note that these methods are derived from the following sources:
Pedregosa et al. (2025), UBC Master of Data Science Program (2025a), UBC
Master of Data Science Program (2025b), UBC Master of Data Science
Program (2025c), and errors from these sources may translate into our
research.

The impact of these findings is significant in practical feature
selection for machine learning. They show the importance of choosing the
most informative features for classification tasks, improving model
performance and simplifying models by focusing on fewer but more
relevant measurements. This can aid in resource efficiency and
interpretability in biological studies, botany, and related scientific
work.

This brings up future questions that could use further research:

\begin{itemize}
\tightlist
\item
  How do more advanced machine learning algorithms (e.g., SVM) compare
  in classification accuracy using petal vs sepal features?
\item
  Can combining petal and sepal features with additional biological or
  environmental data improve model robustness or reveal deeper insights?
\item
  How well do these findings generalize to other flower species or
  datasets---can similar feature importance patterns be found?
\item
  Could unsupervised learning reveal new subgroups or variations in iris
  species beyond the three classical ones using these or other features?
\end{itemize}

In summary, these findings are expected and show the predictive
importance of petal dimensions in iris classification. They have
implications for feature selection and model design, and point to
further possible research on flower classification and its related
biological questions

\subsection{References}\label{references}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-irisUCI}
Fisher, R. A. 1936. {``Iris Dataset.''} UCI Machine Learning Repository.
\url{https://archive.ics.uci.edu/dataset/53/iris}.

\bibitem[\citeproctext]{ref-scikit_learn}
Pedregosa, F., G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O.
Grisel, M. Blondel, et al. 2025. \emph{Scikit-Learn: Machine Learning in
Python}. \url{https://scikit-learn.org/stable/}.

\bibitem[\citeproctext]{ref-dsci531}
UBC Master of Data Science Program. 2025a. {``DSCI 531: Visualization
for Data Science -- Course Notes.''} UBC GitHub Pages.
\url{https://pages.github.ubc.ca/mds-2025-26/DSCI_531_viz-1_students/}.

\bibitem[\citeproctext]{ref-dsci571}
---------. 2025b. {``DSCI 571: Supervised Learning 1 -- Course Notes.''}
UBC GitHub Pages.
\url{https://pages.github.ubc.ca/mds-2025-26/DSCI_571_sup-learn-1_students/}.

\bibitem[\citeproctext]{ref-dsci573}
---------. 2025c. {``DSCI 573: Feature and Model Selection -- Course
Notes.''} UBC GitHub Pages.
\url{https://pages.github.ubc.ca/mds-2025-26/DSCI_573_feat-model-select_students/}.

\end{CSLReferences}




\end{document}
