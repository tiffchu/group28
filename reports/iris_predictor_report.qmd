---
title: IrisSpeciesPredictor
authors: "Tiffany Chu, Gaurang Ahuja, Nguyen Nguyen, Vienne Lee"
format:
  html:
    toc: true
    toc-depth: 3
    embed-resources: true
execute:
  echo: false
  warning: false
  message: false
bibliography: references.bib
---



## Summary
This project investigates whether iris species can be predicted using sepal and petal measurements. After loading and validating the dataset, we explore some basic patterns, do some EDA and then train a model. The overall results show that petal measurements provide strong separation between species, allowing the models to achieve high accuracy.

## Introduction

The Iris dataset is a well-known benchmark in machine learning, containing measurements of iris flowers collected to study how physical characteristics differ across species.

### Feature Summary
There are 4 numerical features in this dataset:

1. `sepal_length`: The length of the sepal (outer part of the flower)
2. `sepal_width`: The width of the sepal
3. `petal_length`: The length of the petal
4. `petal_width`: The width of the petal

There is 1 categorical feature in the dataset:

1. `species`: The target variable (label)

We are using the Iris dataset to answer the question: **“Can we predict the Iris species using petal and sepal measurements?”**

The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class is linearly separable from the other 2; the latter are not linearly separable from each other [@irisUCI].

## Methods & Results

```{python}
#| label: tbl-data
#| tbl-cap: "Preview of Iris Data"
import pandas as pd
data = pd.read_csv("../data/raw/iris.csv")
data.head()
```

### Basic Data Stats
In the code below, we check some basic stats for the dataframe such as the number of rows, columns etc. We convert the columns names to a more standard format using underscores and lowercase. We then check how many unique species there are.

```{python}
train_df = pd.read_csv("../data/processed/iris_train.csv")
train_df_shape = train_df.shape
```

The training dataset has `{python} train_df_shape[0]` rows and `{python} train_df_shape[1]` columns.


### Data Wrangling
Since our goal is classification, this section will look at statistics which will help distinguish between the species. Therefore, we will look at things like mean, median, min, max etc for each feature. This will be followed by graphical analysis where we will explore bar plot, pairwise plot, and boxplot.

```{python}
#| label: tbl-summary-numeric
#| tbl-cap: "Summary of numeric columns"
train_df.describe()
```

```{python}
#| label: tbl-summary-species
#| tbl-cap: "Variation per species"
train_df.groupby("species").agg(["mean", "std"])
```

#### Insights from Data Statistics

From the above tables, we can see:

* Most species have approximately the same number of observations
* Petal measurements display the strongest separation
* Setosa is distinct while versicolor and virginica show some overlap
* Petal dimensions have meaningful differences

## EDA Plots

Below are the plots visualize the underlying patterns, distributions, and relationships within the three features (`sepal_length`, `sepal_width`, `petal_length`, `petal_width`) in the Iris dataset.


### Pairwise Plot
Pairwise plots show the relationships between feature pair and show any clusters. @fig-pairwise helps identify which pair of features show the clearest separation and allows us to identify which features are the most informative for prediction. 

![Pairwise Plot of Iris Features](../results/figures/iris_species_pairwise.png){#fig-pairwise width=90%}

### Boxplot
@fig-boxplot show how each feature varies across species. The median, spread, outliers, and overlaps helps identify features that are most predictive for classifying the Iris species.

![Boxplot of Iris Feature Variation](../results/figures/iris_species_boxplot.png){#fig-boxplot width=60%}

## Model Training Results

We tried 2 models, below are the results of each. 

![Decision Tree Confusion Matrix](../reports/figures/dt_confusion.png){#fig-dt_confusion width=80%}

![K-NN Confusion Matrix](../reports/figures/knn_confusion.png){#fig-knn_confusion width=80%}

## Discussion and Analysis
In our investigation of the Iris dataset, we establish whether these features are strong predictors for Iris species classification and rank their predictive power. This discussion begins with the insights derived from our in-depth exploratory data analysis, then the outcomes of our machine learning models, and finally exploring the implications for biological classification and machine learning practices for future research. \
To summarize the data, the Iris dataset consists of 150 samples with measurements for four features: sepal length, sepal width, petal length, and petal width, across three evenly distributed species: Setosa, Versicolor, and Virginica. 


In our exploratory data analysis (EDA), the summary statistics in @tbl-summary-numeric and @tbl-summary-species show that petal measurements (length and width) exhibit more obvious differences across species compared to sepal feature measurements. Sepal measurements are not as varied across species and thus provide weaker separation when distinguishing species. Our visualizations of pairwise feature plots in @fig-pairwise, and boxplots in @fig-boxplot confirm these patterns, they each reveal the power of petal measurement for distinguishing species during classification. Specifically, the boxplot shows how the species Setosa is easily distinguishable from just its petal measurements. 


Both Decision Tree and KNN models perform strongly on this Iris test set (95% vs 93% accuracy, respectively). Petal and sepal feature differences allow decent separation between species, especially between the species Versicolor and Virginica. The misclassifications in confusion matrices show this overlap. The cross-validation results suggest that Decision Trees with max_depth values from 4 to 18 fit the training data perfectly while achieving similarly high validation accuracy (94.3%) on unseen folds. For the KNN hyperparameter tuning, findings show that choosing n_neighbors between 4 and 12 outputs a classification accuracy around 97% on cross-validation test scores. 


Examining our confusion matrix for model accuracies:

* In the decision tree test performance as seen in @fig-dt_confusion, Setosa was classified perfectly (as it is the most distinguishable), while 3 virginica got misclassified as versicolor. 
* In our KNN model @fig-knn_confusion, we find that setosa is perfect again, and KNN misclassifies: 1 versicolor as virginica, and 2 virginica as versicolor.
* This is expected as the two classes (virginica and versicolor) overlap in features. 


Our decision tree model is slightly better than KNN, with better accuracy, fewer total mistakes, perfect versicolor classification, though same performance on setosa and virginica.
This suggests high but not perfect predictability of iris species from its measurements, with room for improving classification on overlapping species using more advanced methods or additional features.
These results demonstrate a typical well-performing classification pipeline for the Iris dataset, validating the exploratory and modeling insights


The findings that petal measurements strongly separate iris species and have high model accuracy are expected and align with prior knowledge and research on the Iris dataset. The petal length and width consistently show clearer distinctions among the species, particularly separating Setosa from Versicolor and Virginica, however, Sepal measurements tend to show more overlap and offer weaker discriminatory power.


However, there are some limitations associated with our study, some key limitations of the dataset and the related findings include:
The dataset contains only 150 samples with 4 numeric features and 3 species classes, which is considered quite small and simple compared to data on other plant species. This limits the complexity of patterns that can be learned and makes it less applicable to more complex classification tasks. Its size also prevents it from being useful for complex machine learning techniques like deep learning, which require larger datasets.


Only sepal and petal measurements are considered, and other potentially informative features such as genetic data, environmental variables, or flower color are not recorded as features in the data. This constrains prediction to specific traits and may limit generalizability to other flowers or datasets.

It appears that the species Setosa is clearly separable, while Versicolor and Virginica show overlap in some measurements, leading to some classification errors and ambiguity that models must handle or risk making errors. The dataset is clean with no missing values or measurement noise, which is not typical/normal in many real datasets. This means models trained here may be optimistic compared to actual real world performance. So while appropriate for demonstrating classification approaches and feature importance, the Iris dataset's limitations prevent our model from being broadly applicable and generalizable, which must be considered when interpreting and generalizing findings. We must also note that these methods are derived from the following sources: @scikit_learn, @dsci531, @dsci571, @dsci573, and errors from these sources may translate into our research. 


The impact of these findings is significant in practical feature selection for machine learning. They show the importance of choosing the most informative features for classification tasks, improving model performance and simplifying models by focusing on fewer but more relevant measurements. This can aid in resource efficiency and interpretability in biological studies, botany, and related scientific work.

This brings up future questions that could use further research:

* How do more advanced machine learning algorithms (e.g., SVM) compare in classification accuracy using petal vs sepal features?
* Can combining petal and sepal features with additional biological or environmental data improve model robustness or reveal deeper insights?
* How well do these findings generalize to other flower species or datasets—can similar feature importance patterns be found?
* Could unsupervised learning reveal new subgroups or variations in iris species beyond the three classical ones using these or other features?

  
In summary, these findings are expected and show the predictive importance of petal dimensions in iris classification. They have implications for feature selection and model design, and point to further possible research on flower classification and its related biological questions

## References

::: {#refs}
:::

